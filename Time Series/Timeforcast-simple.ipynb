{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df = df[df['item'] == 1]\n",
    "df['date'] = pd.to_datetime(df['date']) - pd.to_timedelta(7, unit='d')\n",
    "df = df.filter(['date', 'sales']).groupby([pd.Grouper(key='date', freq='W-MON')]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shift_sale'] = df['sales'].shift(1)\n",
    "df = df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  sales  shift_sale\n",
      "1 2013-01-07    863       894.0\n",
      "2 2013-01-14    867       863.0\n",
      "3 2013-01-21    816       867.0\n",
      "4 2013-01-28    969       816.0\n",
      "5 2013-02-04    920       969.0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_week_avg(sales):\n",
    "    sum = 0\n",
    "    week_avg = []\n",
    "    for i in range(3, -1, -1):\n",
    "        for j in range(i):\n",
    "            sum += sales[j]\n",
    "        if(i!=0):\n",
    "            week_avg.append(sum/i)\n",
    "        sum = 0\n",
    "    week_avg.append(sales[0])\n",
    "    week_avg.reverse()\n",
    "    for row in range(len(sales) - 4):\n",
    "        for row in range(row, row + 4):\n",
    "            sum += sales[row]\n",
    "        week_avg.append(sum / 4)\n",
    "        sum = 0\n",
    "    return week_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  sales  shift_sale    week_avg\n",
      "1 2013-01-07    863       894.0  863.000000\n",
      "2 2013-01-14    867       863.0  863.000000\n",
      "3 2013-01-21    816       867.0  865.000000\n",
      "4 2013-01-28    969       816.0  848.666667\n",
      "5 2013-02-04    920       969.0  878.750000\n"
     ]
    }
   ],
   "source": [
    "df['week_avg'] = four_week_avg(df['sales'].tolist())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, median_absolute_error, explained_variance_score, max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.iloc[-52:]\n",
    "df = df.iloc[:-52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scikits train_test_split we are going to split the data for training and validation. After we trained our model we first check how it did with the data it trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit results:\n",
      "r2_score -5034.824026185133 \t MSE 232589146.49522856\tEVS -4714.180438254682 \n",
      " MAE 11904.194971074943\tMAD 9053.493520772085\t ME 29094.34086033143\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('sales', axis=1)\n",
    "y = df['sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = svm.SVR(C=1, kernel='linear', degree=8, gamma='scale', coef0=10)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(f'Model fit results:\\n'\n",
    "      f'r2_score {r2_score(y_test, predictions)} \\t MSE {mean_squared_error(y_test, predictions)}'\n",
    "      f'\\tEVS {explained_variance_score(y_test, predictions)} \\n MAE {mean_absolute_error(y_test, predictions)}'\n",
    "      f'\\tMAD {median_absolute_error(y_test, predictions)}\\t ME {max_error(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test results:\n",
      "r2_score -7042.506505757563 \t MSE 539671809.1835542\tEVS -5901.113755525139 \n",
      " MAE 20056.899007223976\tMAD 20273.123977661133\t ME 43620.30727199279\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(test.drop('sales', axis=1))\n",
    "print(f'Model test results:\\n'\n",
    "      f'r2_score {r2_score(test[\"sales\"], predictions)} \\t MSE {mean_squared_error(test[\"sales\"], predictions)}'\n",
    "      f'\\tEVS {explained_variance_score(test[\"sales\"], predictions)} \\n MAE {mean_absolute_error(test[\"sales\"], predictions)}'\n",
    "      f'\\tMAD {median_absolute_error(test[\"sales\"], predictions)}\\t ME {max_error(test[\"sales\"], predictions)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
